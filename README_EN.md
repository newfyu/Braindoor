# ğŸ§   Braindoor

[ä¸­æ–‡](../README.md) | English

## Overview

Braindoor can easily use local files to build ChatGPT's external knowledge base. Support natural language search, Q&A and full text analysis of local documents.

![](doc/fig1.png)

### Use Cases

- Search personal documents or notes with natural language
- Build a domain-specific question answering robot using local text
- Use chatgpt to analyze and answer long text

### Features

- Flexible construction of local knowledge base. Support  txt, md, html, pdf, docx
- Incremental update
- Provides a Web UI. Documents referenced by Search module or Ask module can be opened directly in the browser.
- Full-text deep review

----

### Installation and launch

1ã€Create a python3.9 conda virtual environment

```shell
conda create -n braindoor python=3.9
```

2ã€Install dependent packages

```shell
conda activate braindoor
git clone https://github.com/newfyu/Braindoor.git
cd Braindoor
pip install -r requirements.txt
```

3ã€launch

```shell
python app.py
```

Open "127.0.0.1:7086" in browser and configure your openai key in the Config TAB to work!  

---

### Create a new knowledge base

åœ¨å¤§è„‘é—¨å„¿ä¸­ï¼Œä¸€ä¸ªå‘é‡ä»“åº“åŠå®ƒç´¢å¼•çš„æ–‡ä»¶å¤¹ä¸­çš„æ–‡ä»¶ï¼Œç§°ä¸ºä¸€ä¸ªknowledge baseã€‚     
åœ¨Config --> Create a new knowledge baseä¸­ï¼Œå¡«å†™åº“åå’Œä¸€ä¸ªæœ¬åœ°æ–‡ä»¶å¤¹è·¯å¾„ï¼Œæ–‡ä»¶ç±»å‹å³å¯åˆ›å»ºä¸€ä¸ªknowledge baseã€‚åˆ›å»ºæ—¶åªå…è®¸åŠ å…¥ä¸€ä¸ªæ–‡ä»¶å¤¹ï¼Œä½†åˆ›å»ºæˆåŠŸåå¯ä»¥åœ¨updateä¸­æ·»åŠ æ›´å¤šçš„æ–‡ä»¶å¤¹ã€‚chunk sizeæ˜¯å°†æ–‡ä»¶åˆ‡ç‰‡ååµŒå…¥çš„å¤§å°ï¼Œå¦‚æœä½ å¸Œæœ›è¿›è¡Œé—®ç­”ï¼Œåˆ‡ç‰‡å¤§å°1000-2000æ˜¯åˆé€‚çš„ã€‚è¶…è¿‡2000å®¹æ˜“çªç ´gpt3.5-turboçš„tokené™åˆ¶ã€‚

> ä¾‹ï¼šå‡è®¾æˆ‘æœ‰ä¸€ä¸ªobidianç¬”è®°ä»“åº“ï¼Œè·¯å¾„ä¸º `~/obsidian/myvult`ã€‚ 
> 
> 1. å…ˆå¡«å†™ä¸€ä¸ªçŸ¥è¯†åº“åå¦‚: "mybaseâ€œ
> 2. obsidianåœ°å€ç²˜è´´åˆ° â€œDirectoryâ€œä¸­
> 3. æ–‡ä»¶ç±»å‹é€‰æ‹©"md"å’Œâ€œtxtâ€œ
> 4. ç„¶åç‚¹å‡»CreateæŒ‰é’®

---

### Update existing knowledge base

- When the contents of the indexed folder have changed, click the update button to check the changes and update the vector store.
- After changing some configurations of the knowledge base, you need to click the "Save base config" button
- You can add more index folders for a knowledge base

> ä¾‹ï¼šæˆ‘æƒ³æŠŠæˆ‘çš„å°è±¡ç¬”è®°ä¹ŸåŠ å…¥çŸ¥è¯†åº“ä¸­ã€‚å…ˆä½¿ç”¨å°è±¡ç¬”è®°çš„å¯¼å‡ºåŠŸèƒ½æŠŠæ‰€æœ‰ç¬”è®°ç”¨å•ä¸ªhtmlçš„å½¢å¼å¯¼å‡ºåˆ°æ–‡ä»¶å¤¹`~/evernote` ä¸­ã€‚åœ¨â€œAdd a new directory to current knowledge baseâ€æ–‡æœ¬æ¡†ä¸­ï¼Œå¡«å†™`~/evernote`ï¼Œç±»å‹é€‰æ‹©`html`ã€‚ ç„¶åç‚¹å‡» "Save base config"æŒ‰é’®ã€‚ç¡®è®¤ä¿¡æ¯æ— è¯¯åï¼Œç‚¹å‡»â€œUpdate"æ›´æ–°ã€‚

> Delete a knowledge base: directly delete the corresponding. base file in the bases folder

---

### Search

The search module is used to retrieve your knowledge base. Select a knowledge base and search in any natural language to find similar documents. It supports opening documents directly in the browser.

![](doc/fig2.png)

---

### Ask

- Ask module is a chatbot, which will use the content in your knowledge base as evidence to answer your questions
- By default, the most similar document chunk in the base is referenced
- You can increase the answer depth to allow chatbot to refer to more similar documents
- Support continuous Q & A, but reopen the dialogue on different topics as much as possible
  ![](/doc/fig3.png)

> "Default" means that the local knowledge base is not used, and the original answer of chatgpt is returned.

---

### Review

- After passing in a document, you can freely ask questions about the document
- Unlike Ask, the Review chatbot will not only refer to the document chunk matched by vector similarity, but will read the full text for each question and give the answer
- Full text reading does not omit information, which is slow but powerful
- It is suitable for detailed summary and analysis of a long document or auxiliary reading of literature
- 

![](doc/fig4.png)

> Due to token restrictions, Review canceled the contact context dialog and only responded to the latest request. So every question should be clear and complete

---

### å¼€é”€

The openai key needs to be prepared. The text-ada-001 model is used for create vector store and Search. Ask module use the gpt-3.5-turbo model, both of which cost very little. But be aware, if you have a large knowledge base, be aware of the cost of access. In addition, increasing answer_depth value and frequent use of Review can add overhead depending on the length of the local text.

---

### Configuration

General configuration can be set in the config tab
There are some advanced parameters, which are not recommended to be changed. Modify it in the config.yaml file if necessary

| å‚æ•°å                  | ç±»å‹    | è¯´æ˜                                                                                                                                                                                                                          | é»˜è®¤å€¼   |
| -------------------- | ----- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----- |
| key                  | str   | Fill in your openai key                                                                                                                                                                                                     | â€˜â€˜    |
| rate_limit           | int   | Because openai has a request rate limit, it is easy to restrict access when creating a vector warehouse. 1 means to rest for 1 second after sending a request. It only works when creating and updating the knowledge base. | 1     |
| proxy                | str   | The proxy can be enabled when the openai api is requested. Enter your http proxy address, for example: "http://127.0.0.1:1087"                                                                                              | â€˜â€˜    |
| search_topk          | int   | Applies to the Search module. The number of results returned by the search.                                                                                                                                                 | 20    |
| result_size          | int   | Applies to the Search module. Preview the length of the text.                                                                                                                                                               | 300   |
| answer_depth         | int:  | For Ask. chabot answers with reference to the maximum number of local document chunk.                                                                                                                                       | 1     |
| max_context          | int   | For Ask. The maximum token value of the context.                                                                                                                                                                            | 1000  |
| max_l2               | float | ä½œç”¨äºAskæ¨¡å—ã€‚æœç´¢ç›¸ä¼¼æœ¬åœ°ç‰‡æ®µæ—¶å…è®¸çš„æœ€å¤§L2è·ç¦»ã€‚                                                                                                                                                                                                | 0.4   |
| HyDE                 | bool  | ä½œç”¨äºASKæ¨¡å—ã€‚chatbotåœ¨å‚è€ƒæœ¬åœ°æ–‡æ¡£å‰ï¼Œæ ¹æ®ä½ çš„é—®é¢˜é¢„å…ˆç”¨chatgptç”Ÿæˆä¸€ä¸ªåˆæ­¥å›ç­”ï¼Œç„¶åå†åŒ¹é…ç›¸ä¼¼çš„æœ¬åœ°æ–‡æ¡£ã€‚ä¼šå¢åŠ å‡†ç¡®æ€§ï¼Œä½†ä¹Ÿä¼šå¢åŠ ä¸€ç‚¹å¼€é”€ã€‚                                                                                                                                            | false |
| review_chunk_size    | int   | ä½œç”¨äºReviewæ¨¡å—ï¼Œå¯¹ä¼ å…¥çš„é•¿æ–‡æœ¬åˆ‡ç‰‡æ—¶æ¯å—çš„æœ€å¤§tokenå€¼ã€‚                                                                                                                                                                                          | 2000  |
| review_chunk_overlap | int   | ä½œç”¨äºReviewæ¨¡å—ï¼Œå¯¹ä¼ å…¥çš„é•¿æ–‡æœ¬åˆ‡ç‰‡æ—¶é‡å çš„tokenå€¼ã€‚                                                                                                                                                                                            | 50    |

---

### Main third-party dependencies

- Language model: chatgpt
- Text splitting: langchain
- Vector stores: faiss
- Web interface: gradio
